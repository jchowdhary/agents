AI LLMs pose a significant threat to humanity because they can be exploited for malicious purposes such as misinformation, espionage, and manipulation, leading to societal instability. Their potential for autonomous decision-making without accountability raises risks of unintended harm, including bias and discrimination. Without strict regulation, these systems could be used to infringe on privacy, manipulate public opinion, or even develop autonomous harmful technologies. Therefore, robust regulations are essential to ensure these powerful tools are developed and deployed responsibly, safeguarding societal values and human rights while mitigating existential and security risks.